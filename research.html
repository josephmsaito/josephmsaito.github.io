<!DOCTYPE html>
<html lang="en">
	<head>
		<meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
		<meta name = "format-detection" content = "telephone=no">
		
		<link rel="preconnect" href="https://fonts.googleapis.com">
		<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
		<link href="https://fonts.googleapis.com/css2?family=Manrope:wght@300;400;500;600;700&display=swap" rel="stylesheet">
		<!-- <link href="https://fonts.googleapis.com/css2?family=Manrope:wght@300;400;500;600;700&display=swap" rel="stylesheet" media="print" onload="this.media='all'"> -->

		
		<link rel="apple-touch-icon" sizes="180x180" href="images/favicon_io/apple-touch-icon.png">
		<link rel="icon" type="image/png" sizes="32x32" href="images/favicon_io/favicon-32x32.png">
		<link rel="icon" type="image/png" sizes="16x16" href="images/favicon_io/favicon-16x16.png">
		<!-- <link rel="manifest" href="/site.webmanifest"> -->
		<link rel="manifest" href="images/favicon_io/site.webmanifest" crossorigin="use-credentials">
		<link rel="stylesheet" href="styles.css">
		
		
		<script src="https://code.jquery.com/jquery-3.6.3.min.js" integrity="sha256-pvPw+upLPUjgMXY0G+8O0xUf+/Im1MZjXxxgOcBQBXU=" crossorigin="anonymous"></script>
		<script type="text/javascript">
			$("#wrapper").click( function() {
				$(".icon").toggleClass("close");
			});
		</script>
		
		<script>
			$(document).ready(function(){
			// Add smooth scrolling to all links
			$("a").on('click', function(event) {

				if (this.hash !== "") {
				event.preventDefault();

				// Store hash
				var hash = this.hash;

				$('html, body').animate({
					scrollTop: $(hash).offset().top
				}, 800, function(){
			
					window.location.hash = hash;
				});
				} // End if
			});
			});
		</script>
		

		<script src="nav.js" defer> </script>
		
		<meta name="keywords" content="Joseph, Joey, Joseph Saito, Saito, u of t, university of toronto, fukuda lab"/>
	  	<meta name="description" content="Joseph Saito is a PhD student who is interested in voluntary memory control and the interactions between working memory and long-term memory."/>

		<title>Joseph Saito's Portfolio</title>
		<!-- <meta name="google-site-verification" content="a_czpiTbf41uDmESJeWj--EGPKvYK3vfSuzV8d9wybs" /> -->
	
	
	</head>
	<body>
		
		<header class="primary-header flex opacity-load">
			<div>
				<a href="index.html"><img src="images/favicon/favicon_joey.svg" alt="JS squared favicon logo" class="logo crisp-img"></a>
				<!-- <a href="#home" class="name-header-link"><h1 class="name-header">Joseph Saito</h1></a> -->
			</div>

			<button class="mobile-nav-toggle" aria-controls="primary-navigation" aria-expanded="false">
				<span class="visually-hidden">Menu</span>
				<span class="line top"></span>
				<span class="line middle"></span>
				<span class="line bottom"></span>
			</button>

			<nav>
				<ul id="primary-navigation" data-visible="false" class="primary-navigation flex">
					<li>
						<a href="index.html">Home</a>
					</li>
					<li>
						<a href="about.html">About</a>
					</li>
					<li>
						<a href="research.html">Research</a>
					</li>
					<li>
						<a href="publications.html">Publications</a>
					</li>
					<li>
						<a href="conferences.html">Conferences</a>
					</li>
					<li>
						<a href="cv.html">CV</a>
					</li>
					<li>
						<a href="contact.html">Contact</a>
					</li>
				</ul>
			</nav>
		</header>
		<div class="sidenav opacity-load">
			<!-- <h1 class="sidenav_text_header">PhD Student</h1> -->
			<h2 class="sidenav_text_header">Let's Connect</h2>
			<ul class="sidenav-list">
				<li>
					<a href="mailto:joseph.saito@mail.utoronto.ca" target=”_blank” rel=”noopener noreferrer”><img src="images/icons/email.svg" alt="email" class="crisp-img sidenav-icons"><h1 class="sidenav_text">Email</h1><div class="arrow"></div></a>
				</li>
				<li>
					<a href="https://scholar.google.com/citations?user=EzXVZugAAAAJ&hl=en&oi=ao" target=”_blank” rel=”noopener noreferrer”><img src="images/icons/google_scholar.svg" alt="Google Scholar" class="crisp-img sidenav-icons"><h1 class="sidenav_text">Google Scholar</h1><div class="arrow"></div></a>
				</li>
				<li>
					<a href="https://osf.io/87vah/" target=”_blank” rel=”noopener noreferrer”><img src="images/icons/open_science.svg" alt="Open Science Framework" class="crisp-img sidenav-icons"><h1 class="sidenav_text">OSF</h1><div class="arrow"></div></a>
				</li>
				<li>
					<a href="https://twitter.com/jsaito25" target=”_blank” rel=”noopener noreferrer”><img src="images/icons/twitter.svg" alt="Twitter" class="crisp-img sidenav-icons"><h1 class="sidenav_text">Twitter</h1><div class="arrow"></div></a>
				</li>
			</ul>
			<!-- <a href="#"><img src="images/icons/email.svg" alt="email" class="crisp-img contact-icons"><h1 class="sidenav_text">Email</h1></a>
			<a href="#"><img src="images/icons/open_science.svg" alt="Open Science Framework" class="crisp-img contact-icons"></a>
			<a href="#"><img src="images/icons/google_scholar.svg" alt="Google Scholar" class="crisp-img contact-icons"></a>
			<a href="#"><img src="images/icons/twitter.svg" alt="Twitter" class="crisp-img contact-icons"></a> -->
			
		  </div>

		<div class="grid">
			
			<div class="box1 cell opacity-load" >
				<h1 class="page-heading">Research Overview</h1>
				<h1 class="research-heading">Voluntary regulation of visual long-term memory encoding</h1>
				<p class="research-text">
					<span class=tab-space> </span>In daily life, individuals encounter visual stimuli that they desire to remember and others that they desire to not remember. However, voluntary regulation of memory encoding is asymmetrical across these opposite learning goals. While observers demonstrate a robust ability to up-regulate their encoding of desired stimuli by simply “trying harder” to do so, these same observers struggle to down-regulate their encoding of undesired stimuli. I am currently investigating the limitations of down-regulatory control to discern whether or not this function is possible, and if so, under what circumstances. Thus far, we have found that down-regulation of memory encoding is possible when demands to do so are predictable in time, dovetailing research in other cognitive domains (e.g., visual search) which suggest that suppression of undesired stimuli is influenced by temporal expectations. 
				</p>
				<div class="research-image-container">
					<img src="images/website_schematics/website_schematics-1.webp" alt="Two brains schematic" class="crisp-img research-image">
				</div>
				
				
				<h2 class="research-heading2">Select Contributions:</h2>
				<ul class="research-list">
					<li>
						<p class="research-cite"><b>Saito, J. M.</b> & Fukuda, K. (2023, May). <i>Predictable learning demands enable direct down-regulation of visual long-term memory encoding.</i> Poster presented at the Annual Meeting of the Vision Sciences Society (VSS), St. Petersburg, FL.<br></p>
					</li>
				</ul>
				
				<h1 class="research-heading">The role of perceptual comparisons in visual memory distortion</h1>
				<p class="research-text">
					<span class=tab-space> </span>Comparing visual memories to incoming percepts is fundamental for the detection and discrimination of familiar and novel stimuli. However, such comparisons may come at a cost to memory accuracy. We have demonstrated that comparing visual memories to visual percepts results in attractive biases in subsequent memory reports that are capable of persisting across time from one retrieval episode to the next. The magnitude of these biases is found to be intimately tied to the subjective judgments that are made during the comparison&#8212;biases are smallest when the percept is perceived as “dissimilar”, larger when perceived as “similar”, and largest when mistakenly perceived to be the “same”. Our modeling of these patterns has suggested that these different-sized errors indicate different types of distortion, with those following perceived similarity and dissimilarity reflecting bona fide representational bias and those following perceived sameness reflecting memory replacement by the percept. To this point, the relationship between perceived similarity and memory distortion has largely evaded explanation by several factors known to influence memory bias, including the physical (as opposed to perceived) similarity between memories and percepts, the task-relevance of interfering percepts, trial-wise variability in memory precision, and demand characteristics that encourage intentional biasing of the memory report.
				</p>
				<div class="research-image-container">
					<img src="images/website_schematics/website_schematics-2.webp" alt="Visual working memory schematic" class="crisp-img research-image">
				</div>
				
				<h2 class="research-heading2">Select Contributions:</h2>
				<p class="research-note">* Denotes undergraduate trainee under my supervision</p>

				<ul class="research-list">
					<li>
						<p class="research-cite"><b>Saito, J. M.</b>, Bae, G., & Fukuda, K. (2022, September 15). Judgments during perceptual comparisons predict distinct forms of memory updating. <i>PsyArXiv.</i> <a class="research-text-link" href="https://doi.org/10.31234/osf.io/pfx6v" target=”_blank” rel=”noopener noreferrer”>https://doi.org/10.31234/osf.io/pfx6v<img src="images/icons/hyperlink.svg" alt="Follow link to new tab" class="crisp-img hyperlink-icon"></a></p>
					</li>
					<li>
						<p class="research-cite"><b>Saito, J. M.</b>, Duncan, K., & Fukuda, K. (2023). Comparing visual memories to similar visual inputs risks lasting memory distortion. <i>Journal of Experimental Psychology: General.</i> Advance online publication. <a class="research-text-link" href="https://doi.org/10.1037/xge0001400" target=”_blank” rel=”noopener noreferrer”>https://doi.org/10.1037/xge0001400<img src="images/icons/hyperlink.svg" alt="Follow link to new tab" class="crisp-img hyperlink-icon"></a></p>
					</li>
					<li>
						<p class="research-cite"><b>Saito, J. M.</b>, Kolisnyk, M.*, & Fukuda, K. (2022). Perceptual comparisons modulate memory biases induced by new visual inputs. <i>Psychonomic Bulletin & Review, 30,</i> 291&#8211;302. <a class="research-text-link" href="https://doi.org/10.3758/s13423-022-02133-w" target=”_blank” rel=”noopener noreferrer”>https://doi.org/10.3758/s13423-022-02133-w<img src="images/icons/hyperlink.svg" alt="Follow link to new tab" class="crisp-img hyperlink-icon"></a></p>
					</li>
					<li>
						<p class="research-cite">Fukuda, K., Pereira, A. E., <b>Saito, J. M.</b>, Tang, T. Y., Tsubomi, H., & Bae, G. Y. (2022). Working memory content is distorted by its use in perceptual comparisons. <i>Psychological Science, 33</i>(5), 816&#8211;829. <a class="research-text-link" href="https://doi.org/10.1177%2F09567976211055375" target=”_blank” rel=”noopener noreferrer”>https://doi.org/10.1177%2F09567976211055375<img src="images/icons/hyperlink.svg" alt="Follow link to new tab" class="crisp-img hyperlink-icon"></a></p>
					</li>
				</ul>

				<h1 class="research-heading">Conscious access to intrinsic stimulus memorability</h1>
				<p class="research-text">
					<span class=tab-space> </span>Moment-to-moment fluctuations in cognition place meaningful constraints on our ability to realize the massive storage capacity of long-term memory. Despite this variability across time and individuals, memory encoding success for a given visual stimulus is shown to covary across individuals and learning episodes, suggesting that some visual stimuli are more intrinsically memorable than others. We have found that, for images of objects and faces, observers are consciously aware of how memorable a given stimulus is and are able to use this awareness to form accurate predictions about their subsequent memory performance. Moreover, observers demonstrate this access to memorability even when they are not trying to encode the stimulus, but to a lesser extent than when they are actively engaged in learning. More recently, we have demonstrated that humans and deep neural networks rely on different aspects of a stimulus to inform their predictions of how memorable the stimulus is.
				</p>
				<div class="research-image-container">
					<img src="images/website_schematics/website_schematics-3.webp" alt="Judgements of learning schematic" class="crisp-img research-image">
				</div>
				
				<h2 class="research-heading2">Select Contributions:</h2>
				<ul class="research-list">
					<li>
						<p class="research-cite">Zhao, C., Kim, J., Tang, T. H., <b>Saito, J. M.</b>, & Fukuda, K. (2023, February 18). Deep neural network decodes aspects of stimulus-intrinsic memorability inaccessible to humans. <i>PsyArXiv.</i> <a class="research-text-link" href="https://doi.org/10.31234/osf.io/urz5s" target=”_blank” rel=”noopener noreferrer”>https://doi.org/10.31234/osf.io/urz5s<img src="images/icons/hyperlink.svg" alt="Follow link to new tab" class="crisp-img hyperlink-icon"></a></p>
					</li>
					<li>
						<p class="research-cite"><b>Saito, J. M.</b>, Kolisnyk, M., & Fukuda, K. (2022). Judgments of learning reveal conscious access to stimulus memorability. <i>Psychonomic Bulletin & Review, 30,</i> 317-330. <a class="research-text-link" href="https://doi.org/10.3758/s13423-022-02166-1" target=”_blank” rel=”noopener noreferrer”>https://doi.org/10.3758/s13423-022-02166-1<img src="images/icons/hyperlink.svg" alt="Follow link to new tab" class="crisp-img hyperlink-icon"></a></p>
					</li>
				</ul>



			</div>
			
			

		</div>
	</body>

</html>
